{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb sentence_transformers pandas bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\38641\\Documents\\faks\\5.letnik\\2.semester\\NLP\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a762892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Chroma client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_stackoverflow_db\")\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"stackoverflow_demo\",\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6265237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 questions\n"
     ]
    }
   ],
   "source": [
    "data = ['python_questions0.csv']\n",
    "MAX_DOCS = 1000\n",
    "df = pd.DataFrame()\n",
    "for d in data:\n",
    "    df = pd.concat([df, pd.read_csv(d)], ignore_index=True)\n",
    "\n",
    "    \n",
    "df = df.loc[:min(len(df), MAX_DOCS-1), [\"tags\", \"question_title\", \"question_body\", \"answer\", \"question_score\"]]\n",
    "total_docs = len(df)\n",
    "print(f\"Loaded {total_docs} questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86743d46",
   "metadata": {},
   "source": [
    "Chunking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ec7133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 2282 chunks.\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "min_code_block = 20\n",
    "\n",
    "for ix, content in df.iterrows():\n",
    "    answer = content.loc['answer']\n",
    "    tags = content.loc[\"tags\"]\n",
    "    score = content.loc[\"question_score\"]\n",
    "    chunk = f\"Question: {content.loc['question_body']}\\n{content.loc['question_body']}\\n\\Answer: {answer}\".lower()\n",
    "    metadata = {\"tags\": tags,\n",
    "                \"score\": score,\n",
    "                \"code\": False\n",
    "                }\n",
    "    chunks.append({\"chunk\": chunk,\n",
    "                   \"metadata\": metadata})\n",
    "\n",
    "    soup = BeautifulSoup(answer, 'html.parser')\n",
    "    code_blocks = [code.get_text() for code in soup.find_all('code')]\n",
    "    for block in code_blocks:\n",
    "        if len(block) > min_code_block:\n",
    "            chunks.append({\"chunk\": block.lower(),\n",
    "                           \"metadata\": {\"tags\": tags,\n",
    "                                        \"score\": score,\n",
    "                                        \"code\": True}})\n",
    "\n",
    "chunks = pd.DataFrame(chunks)\n",
    "total_chunks = len(chunks)\n",
    "print(f\"Prepared {total_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4129acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeade83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(current, total, start_time, operation=\"Processing\"):\n",
    "    elapsed = time.time() - start_time\n",
    "    percent = current / total\n",
    "    eta = (elapsed / current) * (total - current) if current > 0 else 0\n",
    "    print(\n",
    "        f\"\\r{operation}: {current}/{total} ({percent:.1%}) | \"\n",
    "        f\"Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s\",\n",
    "        end=\"\", flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e3462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 2282/2282 (100.0%) | Elapsed: 178.0s | ETA: 0.0s\n",
      "\n",
      "Successfully added 2282 documents\n",
      "Total documents in collection: 27164\n",
      "Total time: 178.02 seconds\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 200\n",
    "total_added = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for batch_num in range(0, total_chunks, BATCH_SIZE):\n",
    "    batch = chunks.iloc[batch_num:batch_num + BATCH_SIZE]\n",
    "    \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    for ix, row in batch.iterrows():\n",
    "        chunk = row[\"chunk\"]\n",
    "        metadata = row[\"metadata\"]\n",
    "        documents.append(chunk)\n",
    "        metadatas.append(metadata)\n",
    "        ids.append(str(uuid.uuid4()))  # Generate unique UUID for each document\n",
    "    \n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "    total_added += len(documents)\n",
    "\n",
    "    print_progress(min(batch_num + BATCH_SIZE, total_chunks), total_chunks, start_time)\n",
    "\n",
    "\n",
    "print(f\"\\n\\nSuccessfully added {total_added} documents\")\n",
    "print(f\"Total documents in collection: {collection.count()}\")\n",
    "print(f\"Total time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dbff415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 27164\n",
      "\n",
      "Document 1:\n",
      "ID: 66134e08-ed73-4f4b-a749-befb61095c94\n",
      "Content: Deleting DataFrame row in Pandas based on column value\n",
      "<p>I have the following DataFrame:</p>\n",
      "\n",
      "<pre><code>             daysago  line_race rating        rw    wrating\n",
      " line_date                        ...\n",
      "Metadata: {'score': 256, 'tags': 'python|pandas'}\n",
      "\n",
      "Document 2:\n",
      "ID: 45674e80-94ed-4da7-8fff-880a3e724906\n",
      "Content: Deleting DataFrame row in Pandas based on column value\n",
      "<p>I have the following DataFrame:</p>\n",
      "\n",
      "<pre><code>             daysago  line_race rating        rw    wrating\n",
      " line_date                        ...\n",
      "Metadata: {'score': 256, 'tags': 'python|pandas'}\n",
      "\n",
      "Document 3:\n",
      "ID: e86949ab-473b-426b-ae03-b2a55c57782c\n",
      "Content: What are the differences between numpy arrays and matrices? Which one should I use?\n",
      "<p>What are the advantages and disadvantages of each?</p>\n",
      "\n",
      "<p>From what I've seen, either one can work as a replacem...\n",
      "Metadata: {'tags': 'python|arrays|matrix|numpy', 'score': 256}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = collection.get()\n",
    "print(f\"Total documents: {len(results['ids'])}\")\n",
    "\n",
    "# Inspect first few items\n",
    "for i in range(min(3, len(results['ids']))):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"ID: {results['ids'][i]}\")\n",
    "    print(f\"Content: {results['documents'][i][:200]}...\")  # First 200 chars\n",
    "    print(f\"Metadata: {results['metadatas'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436fbc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 similar questions:\n",
      "\n",
      "Result 1:\n",
      "Score: 0.68\n",
      "Content: import json\n",
      "d =  {'test_0': {'status': 'false', 'test_id': 123453}, \n",
      "      'test_1': {'status': 'false', 'test_id': 123453}, \n",
      "      'test_2': {'status': 'false', 'test_id': 123453}}\n",
      "\n",
      "with open('data.j...\n",
      "Tags: python|json\n",
      "\n",
      "Result 2:\n",
      "Score: 0.68\n",
      "Content: import json\n",
      "d =  {'test_0': {'status': 'false', 'test_id': 123453}, \n",
      "      'test_1': {'status': 'false', 'test_id': 123453}, \n",
      "      'test_2': {'status': 'false', 'test_id': 123453}}\n",
      "\n",
      "with open('data.j...\n",
      "Tags: python|json\n",
      "\n",
      "Result 3:\n",
      "Score: 0.66\n",
      "Content:   import json\n",
      "  data = json.loads(datastring)\n",
      "...\n",
      "Tags: python|json|pdf\n"
     ]
    }
   ],
   "source": [
    "# Search for similar questions\n",
    "query_text = \"how to parse json in python\"\n",
    "query_embedding = model.encode(query_text.lower()).tolist()\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "print(\"\\nTop 3 similar questions:\")\n",
    "for i, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0])):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(f\"Score: {1 - results['distances'][0][i]:.2f}\")\n",
    "    print(f\"Content: {doc[:200]}...\")\n",
    "    print(f\"Tags: {meta['tags']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0805a180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: requests in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 25.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 25.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\38641\\documents\\faks\\5.letnik\\2.semester\\nlp\\ul-fri-nlp-course-project-2024-2025-1-6-3-musketeers\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers --index-url https://download.pytorch.org/whl/cpu\n",
    "! pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d77af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d0044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain Python list comprehensions:\n",
      "\n",
      "List comprehensions are a powerful way to create lists in Python. They allow you to create a list by iterating over a list of values, and then modifying the list in-place. Here's an example:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "my_list_comprehension = [x * 2 for x in my_list]\n",
      "print(my_list_com\n"
     ]
    }
   ],
   "source": [
    "# for testing only\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, embedder, collection, retrieve_number=3):\n",
    "        model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.llm = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cpu\")\n",
    "        self.embedder = embedder\n",
    "        self.retriever = collection\n",
    "        self.retrieve_number = retrieve_number\n",
    "\n",
    "    def generate(self, query):\n",
    "        query_embedding = self.embedder.encode(query.lower()).tolist()\n",
    "        results = self.retriever.query(query_embeddings=[query_embedding], n_results=self.retrieve_number)\n",
    "        prompt = self.build_prompt(results)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "        outputs = self.llm.generate(**inputs, max_new_tokens=100)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    def build_prompt(self, query, results):\n",
    "        context = self.context_from_results(results)\n",
    "        return f'''\n",
    "            Answer the following code related question using the context provided inside triple qoutes in it is useful.\n",
    "            In the answer provide an example of code that is related to the question.\n",
    "            If you do not know the answer, say that you do not know. Do not try to invent the solution.\n",
    "            \n",
    "\n",
    "            Question: {query}\n",
    "\n",
    "\n",
    "            Context: ```{context}´´´\n",
    "\n",
    "            \n",
    "            Answer: \n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c6c037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
